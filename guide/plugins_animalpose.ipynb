{
 "cells": [
  {
   "source": [
    "# Animal Keypoints\n",
    "\n",
    "This section describes the [OpenPifPaf](https://github.com/openpifpaf/openpifpaf) plugin for vehicles. The plugin uses the [Animalpose Dataset](https://sites.google.com/view/animal-pose/). For more information, we suggest to check our latest [paper](https://arxiv.org/abs/2103.02440): <br /> \n",
    "\n",
    "> __OpenPifPaf: Composite Fields for Semantic Keypoint Detection and Spatio-Temporal Association__<br />\n",
    "> _[Sven Kreiss](https://www.svenkreiss.com), [Lorenzo Bertoni](https://scholar.google.com/citations?user=f-4YHeMAAAAJ&hl=en), [Alexandre Alahi](https://scholar.google.com/citations?user=UIhXQ64AAAAJ&hl=en)_, 2021.\n",
    ">\n",
    "\n",
    "\n",
    "## Setup\n",
    "```sh\n",
    "pip3 install openpifpaf\n",
    "pip3 install gdown\n",
    "pip3 install scipy\n",
    "pip3 install thop\n",
    "```\n",
    "\n",
    "(in case CUDA 9 as driver: \n",
    "` pip install torch==1.7.1+cu92 torchvision==0.8.2+cu92 -f https://download.pytorch.org/whl/torch_stable.html`)\n",
    "\n",
    "## Predict\n",
    "Prediction runs as standard openpifpaf predict command, but using the pretrained model on animals.\n",
    "\n",
    "```sh\n",
    "python -m openpifpaf.predict <image path> \\\n",
    "--checkpoint WIP -o\n",
    "```\n",
    "\n",
    "### Preprocess dataset\n",
    "The Animalpose dataset is in a mixed format. Some annotations comes from a collection of keypoints annotations of [PASCAL Dataset](http://host.robots.ox.ac.uk/pascal/VOC/) from UC Berkeley, which the authors of the animalpose dataset have extended. Other annotations have been created by the authors of the dataset. \n",
    "The following instructions will help with downloading and preprocessing the Animalpose dataset.\n",
    "\n",
    "```sh\n",
    "mkdir data\n",
    "mkdir data/animalpose\n",
    "cd data/animalpose\n",
    "pip install gdown\n",
    "gdown https://drive.google.com/uc\\?id\\=1UkZB-kHg4Eijcb2yRWVN94LuMJtAfjEI\n",
    "gdown https://drive.google.com/uc\\?id\\=1zjYczxVd2i8bl6QAqUlasS5LoZcQQu8b\n",
    "gdown https://drive.google.com/uc\\?id\\=1MDgiGMHEUY0s6w3h9uP9Ovl7KGQEDKhJ\n",
    "wget http://host.robots.ox.ac.uk/pascal/VOC/voc2011/VOCtrainval_25-May-2011.tar\n",
    "tar -xvf keypoint_image_part2.tar.gz\n",
    "tar -xvf keypoint_anno_part2.tar.gz\n",
    "tar -xvf keypoint_anno_part1.tar.gz\n",
    "tar -xvf VOCtrainval_25-May-2011.tar\n",
    "rm keypoint_*.tar.gz\n",
    "rm VOCtrainval_25-May-2011.tar\n",
    "```\n",
    "\n",
    "After downloading the dataset, run:\n",
    "`python3 -m openpifpaf_animalpose.voc_to_coco`\n",
    "\n",
    "\n",
    "## Show poses\n",
    "`python -m openpifpaf_apollocar3d.utils.constants`\n",
    "\n",
    "## Pretrained models\n",
    "WIP\n",
    "\n",
    "## Train\n",
    "WIP\n",
    "\n",
    "## Everything else\n",
    "All pifpaf options and commands still stand, please check them in the other page of the guide!\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}